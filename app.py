import streamlit as st
import joblib
import numpy as np
import pandas as pd
import os

# --- 1. ØªØ¹Ø±ÙŠÙ ÙƒÙ„Ø§Ø³ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (Ø¶Ø±ÙˆØ±ÙŠ Ø¬Ø¯Ø§Ù‹ Ù„ÙÙƒ Ø¶ØºØ· Ù…Ù„Ù Ø§Ù„Ù€ pkl) ---
class MyDecisionTree:
    def __init__(self, max_depth=5):
        self.max_depth = max_depth
        self.tree = None

    def predict(self, X):
        return np.array([self._traverse_tree(x, self.tree) for x in X])

    def _traverse_tree(self, x, tree):
        if not isinstance(tree, tuple):
            return tree
        feat_idx, threshold, left, right = tree
        if x[feat_idx] <= threshold:
            return self._traverse_tree(x, left)
        return self._traverse_tree(x, right)

# --- 2. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(page_title="Breast Cancer Predictor", page_icon="ğŸ§¬", layout="wide")

# ØªØµÙ…ÙŠÙ… Ø§Ù„Ù‡ÙŠØ¯Ø± (ØªÙ… ØªØµØ­ÙŠØ­ Ø§Ù„Ù€ Parameter Ù‡Ù†Ø§)
st.markdown("""
    <div style="background-color:#f0f2f6;padding:20px;border-radius:10px;margin-bottom:20px">
    <h1 style="color:#2e4053;text-align:center;">ğŸ§¬ Ù†Ø¸Ø§Ù… ØªØ´Ø®ÙŠØµ Ø³Ø±Ø·Ø§Ù† Ø§Ù„Ø«Ø¯ÙŠ Ø§Ù„Ø°ÙƒÙŠ</h1>
    <p style="text-align:center;">Ø¥Ø¯Ø®Ø§Ù„ ÙŠØ¯ÙˆÙŠ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ùˆ Ø±ÙØ¹ Ù…Ù„ÙØ§Øª Ø´Ø§Ù…Ù„Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ù…Ø§Ø¹ÙŠ</p>
    </div>
    """, unsafe_allow_html=True)

# --- 3. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ---
model_path = 'models/my_tree_model.pkl'

@st.cache_resource
def load_model():
    if os.path.exists(model_path):
        try:
            return joblib.load(model_path)
        except:
            return None
    return None

model = load_model()

# Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù€ 30 Ù…ÙŠØ²Ø© Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„ØµØ­ÙŠØ­ Ø§Ù„Ø°ÙŠ ØªØ¯Ø±Ø¨ Ø¹Ù„ÙŠÙ‡ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
feature_names = [
    'mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 
    'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension',
    'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 
    'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error',
    'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', 
    'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension'
]

if model is None:
    st.error(f"âŒ Ù…Ù„Ù Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ: {model_path}")
    st.stop()

# --- 4. Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ---
tab1, tab2 = st.tabs(["âœï¸ ÙØ­Øµ Ø­Ø§Ù„Ø© ÙˆØ§Ø­Ø¯Ø©", "ğŸ“ ØªØ­Ù„ÙŠÙ„ Ù…Ù„Ù (Batch Mode)"])

# --- Ø§Ù„ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø£ÙˆÙ„: Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„ÙŠØ¯ÙˆÙŠ ---
with tab1:
    st.info("Ø£Ø¯Ø®Ù„ Ù‚ÙŠÙ… Ø§Ù„Ù…ÙŠØ²Ø§Øª (Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹ ØªÙ… ÙˆØ¶Ø¹ Ù‚ÙŠÙ… Ù„Ø­Ø§Ù„Ø© Ø­Ù…ÙŠØ¯Ø©):")
    
    # Ù‚ÙŠÙ… Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¢Ù…Ù†Ø© (ØªÙ…Ø«Ù„ Ø­Ø§Ù„Ø© Ø­Ù…ÙŠØ¯Ø© ØªÙ‚Ø±ÙŠØ¨ÙŠØ§Ù‹)
    defaults = [12.0, 18.0, 75.0, 450.0, 0.09, 0.08, 0.04, 0.02, 0.17, 0.06] * 3 
    
    user_inputs = []
    cols = st.columns(3) 
    for i, name in enumerate(feature_names):
        with cols[i % 3]:
            val = st.number_input(f"{name}", value=float(defaults[i]), format="%.4f", key=f"manual_{i}")
            user_inputs.append(val)

    if st.button('Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„ØªØ´Ø®ÙŠØµ Ø§Ù„ÙŠØ¯ÙˆÙŠ ğŸ”'):
        features = np.array(user_inputs).reshape(1, -1)
        prediction = model.predict(features)[0]
        
        st.divider()
        if prediction == 0:
            st.error("### Ø§Ù„Ù†ØªÙŠØ¬Ø©: ÙˆØ±Ù… Ø®Ø¨ÙŠØ« (Malignant) âš ï¸")
        else:
            st.success("### Ø§Ù„Ù†ØªÙŠØ¬Ø©: ÙˆØ±Ù… Ø­Ù…ÙŠØ¯ (Benign) âœ…")
            st.balloons()

# --- Ø§Ù„ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø«Ø§Ù†ÙŠ: Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù ---
with tab2:
    st.subheader("ØªØ­Ù„ÙŠÙ„ Ø¹ÙŠÙ†Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©")
    st.markdown("""
    Ø§Ø±ÙØ¹ Ù…Ù„Ù CSV ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù€ 30 Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ù„Ø¹Ù…ÙˆØ¯ Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ø¨Ø§Ø³Ù… **Name**.
    """)
    
    uploaded_file = st.file_uploader("Ø§Ø®ØªØ± Ù…Ù„Ù CSV", type="csv")
    
    if uploaded_file is not None:
        try:
            df = pd.read_csv(uploaded_file)
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            missing_cols = [c for c in feature_names if c not in df.columns]
            
            if not missing_cols:
                # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØ¶Ù…Ø§Ù† Ø£Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø±Ù‚Ø§Ù…
                X_batch = df[feature_names].values
                preds = model.predict(X_batch)
                
                # Ø¨Ù†Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                res_df = pd.DataFrame({
                    'Ø§Ù„Ø§Ø³Ù…': df['Name'] if 'Name' in df.columns else "Ù…Ø±ÙŠØ¶ Ù…Ø¬Ù‡ÙˆÙ„",
                    'Ø§Ù„ØªØ´Ø®ÙŠØµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ': ["Ø®Ø¨ÙŠØ« âš ï¸" if p == 0 else "Ø­Ù…ÙŠØ¯ âœ…" for p in preds]
                })
                
                # Ø¯Ù…Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù„Ù„Ø¹Ø±Ø¶
                final_output = pd.concat([res_df, df[feature_names]], axis=1)
                
                st.success(f"âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ {len(df)} Ø­Ø§Ù„Ø© Ø¨Ù†Ø¬Ø§Ø­!")
                st.dataframe(final_output, use_container_width=True)
                
                # Ø²Ø± Ø§Ù„ØªØ­Ù…ÙŠÙ„
                csv_file = final_output.to_csv(index=False).encode('utf-8-sig')
                st.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬ CSV", csv_file, "diagnosis_report.csv", "text/csv")
            else:
                st.error(f"âŒ Ø§Ù„Ù…Ù„Ù ÙŠÙ†Ù‚ØµÙ‡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©: {', '.join(missing_cols)}")
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù: {e}")